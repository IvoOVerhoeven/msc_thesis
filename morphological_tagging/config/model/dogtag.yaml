batch_first: True
transformer_dropout: 0.1
embedding_dropout: 0.5
mha_kwargs:
  n_heads: 16
  dropout: 0.25
rnn_kwargs:
  num_layers: 3
  residual: True
  dropout: 0.5
  rnn_type: "lstm"
  bidirectional: True
label_smoothing: 0.03
mask_p: 0.00
transformer_lrs:
  char_embeddings: 0.0
  initial_char_encoder: 5.0e-6
  chars_to_molecules: 5.0e-6
  encoder: 1.0e-5
  projection: 5.0e-5
  final_char_encoder: 5.0e-5
  pooler: 5.0e-5
rnn_lr: 1.0e-3
clf_lr: 2.5e-3
n_warmup_steps: 0.08
optim_kwargs:
  betas:
    - 0.9
    - 0.98
  weight_decay: 1.0e-1
unfreeze_transformer_epoch: 1
